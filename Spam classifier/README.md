# Spam classifier

Написал небольшой простой классификатор спама.
Основан на этом корпусе: **Apache SpamAssassin’s public datasets** https://spamassassin.apache.org/old/publiccorpus/ 
(Гит, к сожалению, противится загрузке папки с корпусом, так как в ней что-то типа >3к файлов)

Натренировал обычную лог. регрессию, увеличив только макс. количество итераций (на стандартных 100 что-то шло не так). 
Выдаёт на удивление хорошие результаты: accuracy = 0.97, precision = 0.96 на "сложных" примерах (подробнее в документации корпуса). Кросс-валидацию проводил — тоже даёт секси результаты
Препроцессинг состоял из удаления пунктуации, стоп-слов, замены ссылок на тег URL и чисел на тег NUM, лемматизации. Векторные представления слов — на основе Bag of words.

Посмотрел зависимость от некоторых гиперпараметров препроцессора.
Лучше всего, на удивление, работает без удаления стоп слов:
![alt text](https://github.com/vchemsmisl/random-practice/blob/spam/Spam%20classifier/result%20del_sw%3DFalse.png)

А вот так со стоп-словами:
![alt text](https://github.com/vchemsmisl/random-practice/blob/spam/Spam%20classifier/result%20del_sw%3DTrue.png)

Также попробовал увеличить размер n-граммы для создания векторов, но чото такое себе. Вот как стало при ngram_range=(2, 3):
![alt text](https://github.com/vchemsmisl/random-practice/blob/spam/Spam%20classifier/result%20ngram_range%3D(2%2C%203).png)


Есть проблема: препроцессор работает очень медленно (~минут 15). Из решений приходит в голову стемминг вместо лемматизации и делать векторы поменьше. 
Ещё было бы неплохо отрезать headersы у писем. Если будет не лень — доделаю.
